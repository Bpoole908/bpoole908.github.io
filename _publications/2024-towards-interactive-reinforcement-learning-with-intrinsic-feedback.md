---
title: "Towards Interactive Reinforcement Learning with Intrinsic Feedback"
collection: publications
permalink: /publication/2024-towards-interactive-reinforcement-learning-with-intrinsic-feedback
excerpt: ''
date: 2024-07-28
venue: 'Neurocomputing'
paperurl: 'https://doi.org/10.1016/j.neucom.2024.127628'
citation: 'Poole, B., & Lee, M. (2021). Towards interactive reinforcement learning with intrinsic feedback. <i>Neurocomputing, 587</i>, 127628.'
---
Reinforcement learning (RL) and brain–computer interfaces (BCI) have experienced significant growth over the past decade. With rising interest in human-in-the-loop (HITL), incorporating human input with RL algorithms has given rise to the sub-field of interactive RL. Adjacently, the field of BCI has long been interested in extracting informative brain signals from neural activity for use in human–computer interactions. A key link between these fields lies in the interpretation of neural activity as feedback such that interactive RL approaches can be employed. We denote this new and emerging medium of feedback as intrinsic feedback. Despite intrinsic feedback’s ability to be conveyed automatically and even unconsciously, proper exploration surrounding this key link has largely gone unaddressed by both communities. Thus, to help facilitate a deeper understanding and a more effective utilization, we provide a tutorial-style review covering the motivations, approaches, and open problems of intrinsic feedback and its foundational concepts.